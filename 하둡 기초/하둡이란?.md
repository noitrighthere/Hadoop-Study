# 빅데이터의 개념

* 기존 데이터베이스 관리도구의 데이터 수집, 저장, 관리, 분석하는 역량을 넘어서는 데이터
* 다양한 종류의 대규모 데이터로부터 저렴한 비용으로 가치를 추출하고, 데이터의 빠른 수집, 발굴, 분석을 지원하도록 고안된 차세대 기술 및 아키텍처

## 빅데이터의 3대 요소

![빅데이터의 3대 요소](/img/하둡_기초/빅데이터_3대_요소.png "빅데이터 3대 요소")

빅데이터의 3대 요소란 크기(Volume), 속도(Velocity), 다양성(Variety)을 의미하며, 각 요소에는 다음과 같은 특징이 있다.

* 크기(Volume)  
빅데이터는 기존 파일 시스템에 저장하기 어려울뿐더러 데이터 분석을 위해 사용하는 기존 데이터웨어하우스(DW) 같은 솔루션에서 소화하기 어려울 정도로 급격하게 데이터의 양이 증가하고 있다. 이러한 문제를 극복하려면 확장 가능한 방식으로 데이터를 저장하고 분석하는 분산 컴퓨팅 기법으로 접근해야 한다.

* 속도(Velocity)  
빅데이터의 속도적인 특징은 크게 실시간 처리와 장기적인 접근으로 나눌 수 있다. 또한 디지털 데이터는 매우 빠른 속도로 생성되기 때문에 데이터의 생산, 저장, 유통, 수집, 분석이 실시간으로 처리돼야 한다.  
수집된 대량의 데이터를 다양한 분석 기법과 표현 기술로 분석해야 하고, 장기적이고 전략적인 차원에서 접근할 필요가 있다.

* 다양성(Variety)  
다양한 종류의 데이터들이 빅데이터를 구성하고 있다. 데이터 정혀화의 종류에 따라 정형(structured), 반정형(semi-structured), 비정형(unstructured)으로 나눌 수 있다.

## 하둡이란?

**하둡**은 대용량  데이터를 분산 처리할 수 있는 자바 기반의 오픈소스 프레임워크이다. 하둡은 분산 파일 시스템인 HDFS(Hadoop Distributed File System)에 데이터를 저장하고, 분산 처리 시스템인 맵리듀스를 이용해 데이터를 처리한다.

빅데이터를 처리할 때 하둡을 사용하는 이유는 다음과 같다.

* 하둡은 오픈소스 프로젝트이기에 소프트웨어 라인서스 비용에 대한 부담이 없다.
* 리눅스 서버면 얼마든지 하둡을 설치해서 운영할 수 있다.
* 하둡은 데이터의 복제본을 저장하기 때문에 데이터의 유실이나 장애가 발생했을 때도 데이터 복구가 가능하다.

## 하둡 에코시스템

하둡은 비즈니스에 효율적으로 적용할 수 있게 다양한 서브 프로젝트를 제공한다. 이러한 서브 프로젝트가 상용화되면서 **하둡 에코시스템(Hadoop Ecosystem)** 이 구성됐다. 분산 데이터를 저장하는 HDFS와 분석 데이터를 처리하는 맵리듀스가 하둡 코어 프로젝트에 해당하고, 나머지 프로젝트는 모두 하둡의 서브 프로젝트이다.

![하둡 에코시스템](/img/하둡_기초/하둡_에코시스템.png "하둡 에코시스템")

### 코디네이터

* Zookeeper  
분산 환경에서 서버 간의 상호 조정이 필요한 다양한 서비스를 제공하는 시스템으로 크게 다음과 같은 네 가지 역활을 수행한다.  
첫째, 하나의 서버에만 서비스가 집중되지 않게 서비스를 알맞게 분산해 동시에 처리하게 해준다.  
둘째, 하나의 서버에서 처리한 결과를 다른 서버와도 동기화해서 데이터의 안정성을 보장한다.  
셋째, 운영(active) 서버에 문제가 발생해서 서비스를 제공할 수 없을 경우, 다른 대기 중인 서버를 운영 서버로 바꿔서 서비스가 중지 없이 제공되게 한다.  
넷째, 분산 환경을 구성하는 서버의 환경설정을 통합적으로 관리한다.

### 리소스 관리

* YARN  
얀(YARN)은 데이터 처리 작업을 실행하기 위한 클러스터 자원(CPU, 메모리, 디스크 등)과 **스케쥴링을 위한 프레임워크**이다. 기존 하둡의 데이터 처리 프레임워크인 **맵리듀스의 단점을 극복하기 위해 시작된 프로젝트**이며, 하둡 2.0부터 이용할 수 있다.

* Mesos  
**메소스는 클러스터링 환경에서 동적으로 자원을 할당하고 격리하는 메커니즘을 제공하며, 이를 통해 분산 환경에서 작업 실행을 최적화**할 수 있다.

### 데이터 저장

* HBase   
HDFS 기반의 컬럼 기반 데이터베이스이다. **실시간 랜덤 조회 및 업데이트가 가능**하며, 각 프로세스는 개인의 데이터를 비동기적으로 업데이트할 수 있다.

* Kudu  
쿠두(Kudu)는 컬럼 기반의 스토리지로서, **특정 컬럼에 대한 데이터 읽기를 고속화할 수 있다.**

### 데이터 수집

* Chuckwa  
척와(Chuckwa)는 분산 환경에서 생성되는 데이터를 HDFS에 안정적으로 저장하는 플랫폼이다. 분산된 각 서버에서 에이전트(agent)를 실행하고, 콜렉터(collector)가 에이전트로부터 데이터를 받아 HDFS에 저장한다.

* Flume  
플럼(Flume)은 척와처럼 분산된 서버에 에이전트가 설치되고, 에이전트로부터 데이터를 전달받는 콜렉터로 구성한다. 차이점은 전체 데이터의 흐름을 관리하는 마스터 서버가 있어서 데이터를 어디서 수집하고 어떤 방식으로 전송하고, 어디에 저장할지를 동적으로 변경할 수 있다.

* Scribe  
페이스북에서 개발한 데이터 수집 플랫폼이며, Chuckwa와는 다르게 데이터를 중앙 집중 서버로 전송하는 방식이다.

* Sqoop  
스쿱(Sqoop)은 대용량 데이터 전송 솔루션이다. HDFS, RDBMS, DW, NoSQL 등 다양한 저장소에 대용량 데이터를 신속하게 전송하는 방법을 제공한다.

* Kafka  
카프카(Kafka)는 **데이터 스트림을 실시간으로 관리**하기 위한 분산 메세지 시스템이다. **대용량 이벤트처리를 위해 개발**됐다.

### 데이터 처리

* Pig  
피그(Pig)는 **복잡한 맵리듀스 프로그래밍을 대쳏ㄹ 피그 라틴(Pig Latin)이라는 자체 언어를 제공**한다.

* Mahout  
머하웃(Mahout)은 하둡 기반으로 데이터 마이닝 알고리즘을 구현한 오픈소스 프로젝트이다. 현재 분류(classification), 클러스터링(clustering), 추천 및 협업 필터링(Recommenders/collaborative filtering) 등 주요 알고리즘을 지원한다.

* Spark  
스파크(Spark)는 **인메모리 기반의 범용 데이터 처리 플랫폼**이다. 배치 처리, 머신러닝, SQL 질의 처리, 스트리밍 데이터 처리, 그래프 라이브러리 처리와 같은 다양한 작업을 수용할 수 있도록 설계돼 있다.

* Impala  
임팔라(Impala)는 하둡 기반의 분산 쿼리 엔진이다. 맵리듀스를 사용하지 않고, C++로 개발한 인메모리 엔진을 사용해 빠른 성능을 보여준다.

* Presto  
프세스토(Presto)는 대화형 질의를 처리하기 위한 분산 쿼리 엔진이다. 메모리 기반으로 데이터를 처리하며, 다양한 데이터 저장소에 저장된 데이터를 SQL로 처리할 수 있다.

* Hive  
하이브(Hive)는 하둡 기반의 데이터웨어하우징용 솔루션이다. SQL과 매우 유사한 HiveQL이라는 쿼리 언어를 제공한다.

* Tajo  
타조(Hajo)는 하둡 기반의 데이터 웨어하우스 시스템이다. 맵리듀스 엔진이 아닌 자체 분산 처리 엔진을 사용하며, HiveQL을 사용하는 다른 시스템과는 다르게 표준 SQL을 지원하는 것이 특징이다.

### 데이터 시각화

* Zeppelin  
제플린(Zeppelin)은 빅데이터 분석가를 위한 웹 기반의 분석 도구이며 분석 결과를 즉시 표, 그래프로 표현하는 시각화까지 지원한다. **스파크, 하이브, 타조, 플링크(Flink), 엘라스틱 서치, 카산드라, DBMS 등 다양한 분석 플랫폼과 연동할 수 있다.**